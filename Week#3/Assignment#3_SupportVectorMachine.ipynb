{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import time\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "diabetes = pd.read_csv('./data/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.drop('Outcome',axis=1).plot(kind='box', subplots=True, layout=(2,4), sharex=False, sharey=False, figsize=(9,9), \n",
    "                                        title='Box Plot for each input variable')\n",
    "plt.savefig('diabetes_box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training and Test Sets and Apply Scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = diabetes.drop(['Outcome'],axis=1)\n",
    "y = diabetes['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Models\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
    "     .format(lda.score(X_train, y_train)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
    "     .format(lda.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(X_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm  \n",
    "C = 1.0  # SVM regularization parameter\n",
    "\n",
    "# SVC with linear kernel\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X_train, y_train)\n",
    "print('\\n SVC with linear kernel')\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svc.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svc.score(X_test, y_test)))\n",
    "\n",
    "# LinearSVC (linear kernel)\n",
    "lin_svc = svm.LinearSVC(C=C).fit(X_train, y_train)\n",
    "print('\\n LinearSVC (linear kernel)')\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(lin_svc.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(lin_svc.score(X_test, y_test)))\n",
    "\n",
    "# SVC with RBF kernel\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(X_train, y_train)\n",
    "print('\\n SVC with RBF kernel')\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(rbf_svc.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(rbf_svc.score(X_test, y_test)))\n",
    "\n",
    "# SVC with polynomial (degree 3) kernel\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(X_train, y_train)\n",
    "print('\\n SVC with polynomial (degree 3) kernel')\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(poly_svc.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(poly_svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm  \n",
    "X = diabetes.drop(['Outcome'],axis=1)\n",
    "y = diabetes['Outcome']\n",
    "C = 1.0  # SVM regularization parameter\n",
    " \n",
    "# SVC with linear kernel\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X, y)\n",
    "# LinearSVC (linear kernel)\n",
    "lin_svc = svm.LinearSVC(C=C).fit(X, y)\n",
    "# SVC with RBF kernel\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(X, y)\n",
    "# SVC with polynomial (degree 3) kernel\n",
    "poly_svc = svm.SVC(kernel='poly', degree=2, C=C).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "\t  'LinearSVC (linear kernel)',\n",
    "\t  'SVC with RBF kernel',\n",
    "\t  'SVC with polynomial (degree 3) kernel']\n",
    " \n",
    " \n",
    "for i, clf in enumerate((svc, lin_svc, rbf_svc, poly_svc)):\n",
    "  # Plot the decision boundary. For that, we will assign a color to each\n",
    "  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "  plt.subplot(2, 2, i + 1)\n",
    "  plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "  Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "  # Put the result into a color plot\n",
    "  Z = Z.reshape(xx.shape)\n",
    "  plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "  # Plot also the training points\n",
    "  plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "  plt.xlabel('width')\n",
    "  plt.ylabel('height ')\n",
    "  plt.xlim(xx.min(), xx.max())\n",
    "  plt.ylim(yy.min(), yy.max())\n",
    "  plt.xticks(())\n",
    "  plt.yticks(())\n",
    "  plt.title(titles[i])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
